---
title: "P8105 HW 3"
author: Yuki Low (yl5503)
date: 09/15/2023
output: github_document
---

Loading necessary packages
```{r, message = FALSE}
library(p8105.datasets)
library(dplyr)
library(ggplot2)
library(tidyr)
library(readr)
library(stringr)
```

**Problem 1**

Loading the Instacart dataset 
```{r}
data("instacart")
head(instacart)
```

The Instacart dataset contains information about online grocery orders made through the Instacart platform. There are $`r nrow(instacart)`$ observations in the Instacart dataset. It includes data on items ordered, the aisle they belong to, order times, and more. The dataset is structured as a data frame and consists of several columns, including `order_id`, `product_id`, `aisle_id`, `aisle`, `product_name`, `order_hour_of_day`, `order_dow`, and `order_count`.

1. Using the unique function to gather all of the unique aisle names and the length function to count how many unique aisle names there are in total
2.  `aisle_df` is a dataset that allows us to see how many orders were ordered from each unique aisle
3.  `aisle_df` is arranged in descending order 

```{r}
num_aisles <- length(unique(instacart$aisle))
aisle_df <- instacart %>% 
  group_by(aisle) %>% 
  summarise(count = n()) %>% 
  arrange(desc(count))
head(aisle_df)
```

There are $`r num_aisles`$ aisles. The aisles that more items are ordered from are fresh vegetables ($150609$ orders) and fresh fruits ($150473$ orders). 

1. `aisle_10000` is a subset of the original `aisle_df` and shows us only the aisles where there were more than $10000$ orders

```{r}
aisle_10000 <- aisle_df %>% 
  filter(count > 10000)

ggplot(aisle_10000, aes(x = reorder(aisle, count), y = count)) +
  geom_bar(stat = "identity", fill = "skyblue") + 
  labs(
    title = "Barplot Showing Number of Orders from Each Aisle",
    x = "Aisle Names",
    y = "Count"
  ) +
  coord_flip()
```

1. `baking_ingredients` is a subset of the `instacart` df and looks at only the orders from the aisle named "baking ingredients" 
2. The resulting  `baking_ingredients` dataframe shows us a product name and the number of times that it has been ordered 
3.  `baking_ingredients` is ordered in descending order 

```{r}
baking_ingredients <- subset(instacart, aisle == "baking ingredients")
baking_ingredients <- baking_ingredients %>% 
  group_by(product_name) %>% 
  summarise(count = n()) %>% 
  arrange(desc(count))
head(baking_ingredients)
```

1. `dog_food_care` is a subset of the `instacart` df and looks at only the orders from the aisle named "dog food care" 
2. The resulting  `dog_food_care` dataframe shows us a product name and the number of times that it has been ordered 
3.  `dog_food_care` is ordered in descending order 

```{r}
dog_food_care <- subset(instacart, aisle == "dog food care")
dog_food_care <- dog_food_care %>% 
  group_by(product_name) %>% 
  summarise(count = n()) %>% 
  arrange(desc(count))
head(dog_food_care)
```

1. `packages_veg_fruits` is a subset of the `instacart` df and looks at only the orders from the aisle named "packaged vegetables fruits" 
2. The resulting  `packages_veg_fruits` dataframe shows us a product name and the number of times that it has been ordered 
3.  `packages_veg_fruits` is ordered in descending order 

```{r}
packages_veg_fruits <- subset(instacart, aisle == "packaged vegetables fruits")
packages_veg_fruits <- packages_veg_fruits %>% 
  group_by(product_name) %>% 
  summarise(count = n()) %>% 
  arrange(desc(count))
head(packages_veg_fruits)
```

1. A separate dataframe was created for each of three aisles. Each dataframe includes the top three items that were ordered 
2. A column noting which aisle the item belonged to was added to each dataframe 
3. The function `rbind` was used to combine the three dataframes into one final df 
4. The function `kable` in the package `knitr` was used to format the table nicely
5. The resulting df called `top_3_df` contains the top three items that were ordered and which aisle the item was ordered from 

```{r}
top_baking_ingredients <- head(baking_ingredients[order(baking_ingredients$count, decreasing = TRUE), ], 3)
top_dog_food_care <- head(dog_food_care[order(dog_food_care$count, decreasing = TRUE), ], 3)
top_packaged_vegetables_fruits <- head(packages_veg_fruits[order(packages_veg_fruits$count, decreasing = TRUE), ], 3)

top_baking_ingredients <- top_baking_ingredients %>% 
  mutate(aisle = "baking ingredients")

top_dog_food_care <- top_dog_food_care %>% 
  mutate(aisle = "dog food care")

top_packaged_vegetables_fruits <- top_packaged_vegetables_fruits %>% 
  mutate(aisle = "packaged vegetables fruits")

top_3_df <- rbind(top_baking_ingredients,top_dog_food_care,top_packaged_vegetables_fruits)

knitr::kable(top_3_df)
```


1. `filtered_orders` is a subset of `instacart` in which we only want to look at the information relating to pink lady apples and coffee ice cream. 
2. `mean_hour_table` shows us the mean hour of the day that the product was ordered on each day of the week 
3. The function `pivot_wider` and `colnames` was used to widen the dataframe so that the column names were each day of the week and each of the two rows correspond to coffee ice cream and pink lady apple respectively 

```{r, warning = FALSE}
filtered_orders <- instacart %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream"))

mean_hour_table <- filtered_orders %>%
  group_by(product_name, order_dow) %>%
  summarize(mean_hour = mean(order_hour_of_day, na.rm = TRUE))

mean_hour_table <- mean_hour_table %>%
  pivot_wider(names_from = order_dow, values_from = mean_hour) %>%
  arrange(product_name)

colnames(mean_hour_table) <- c("Product", "Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday")

knitr::kable(mean_hour_table)
```

2. 

*Cleaning the data* 

1. Load the dataset 
2. Clean the dataset column names 
3. We want to subset the data to only include the `topic` of "Overall Health" 
4. We want only `response` values from Poor-Excellent 
5. Change the response variable to an ordered variable from Poor to Excellent

```{r}
library(p8105.datasets)
data("brfss_smart2010")
brfss_smart2010<- brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  subset(topic == "Overall Health") %>% 
  subset(response %in% c("Poor", "Fair", "Good", "Very Good", "Excellent"))

brfss_smart2010$response <- factor(brfss_smart2010$response, levels = c("Poor", "Fair", "Good", "Very Good", "Excellent"), ordered = TRUE)

head(brfss_smart2010)
```

```{r}
state_location_counts_2002 <- brfss_smart2010 %>% 
  filter(year == 2002) %>% 
  group_by(locationabbr) %>% 
  summarise(number_of_cities = n_distinct(locationdesc)) %>% 
  filter(number_of_cities >= 7)
state_location_counts_2002
```

In 2002, CT, FL, MA, NC, NJ and PA were observed 7 or more locations.

```{r}
state_location_counts_2010 <- brfss_smart2010 %>% 
  filter(year == 2010) %>% 
  group_by(locationabbr) %>% 
  summarise(number_of_cities = n_distinct(locationdesc)) %>% 
  filter(number_of_cities >= 7)
head(state_location_counts_2010)
```
In 2010, CA, CO, FL, MA, MD, NC, NE, NJ, NY, OH, PA, SC, TX, WA were observed at 7 or more locations. 


`excellent_df` is a dataset that is limited to only excellent responses and contains, the year, the state and the variable named `avg_data_value` whihc averages the `data_value` across locations within a state. 
```{r}
excellent_df <- brfss_smart2010 %>% 
  filter(response == "Excellent") %>% 
  group_by(year, locationdesc) %>%
  summarize(avg_data_value = mean(data_value, na.rm = TRUE))

head(excellent_df)
```

```{r}
ggplot(excellent_df, aes(x = year, y = avg_data_value, group = locationdesc)) +
  geom_point() + 
  geom_line() +
  labs(
    title = "Average Excellent Responses Over Time by State",
    x = "Year",
    y = "Average Data Value"
  )

```

`ny_data_2006_2010` is a dataset that is a subset of `brfss_smart_2010` that filters out only New York and years 2006 or 2010 data_values. The following is a two panel plot showing, for the years 2006 and 2010, the distribution of the data_value for responses ("Poor" to "Excellent") among locations in New York State. 

```{r}
ny_data_2006_2010 <- brfss_smart2010 %>%
  filter(locationabbr == "NY" & (year == "2006" | year == "2010")) %>%
  ggplot(aes(x = data_value)) + 
  geom_histogram(binwidth = 3) + 
  facet_grid(year ~response)

ny_data_2006_2010
```

3. 

Loading the necessary CSV files into R 
```{r}
accel_df = 
  read_csv("./nhanes_accel.csv") %>%
  janitor::clean_names()

covar_df = 
  read_csv("./nhanes_covar.csv") %>%
  janitor::clean_names()

head(covar_df)
```
Changing column names and deleting first 4 rows, deleting rows with NA's 
```{r}
colnames(covar_df) <- covar_df[4, ]
covar_df <- covar_df[-c(1:4), ]
covar_df<- na.omit(covar_df)
```

Changing sex and education to factor variables, age, BMI and seqn to integer variables 
```{r}
covar_df <- 
  covar_df %>% 
  mutate(sex = as.factor(sex)) %>%
  mutate(education = as.factor(education)) %>% 
  mutate(age = as.numeric(age)) %>% 
  mutate(BMI = as.numeric(BMI)) %>% 
  rename(seqn = SEQN) %>% 
  mutate(seqn = as.double(seqn))
```

`summary_table` shows the number of men and women in each education category. 
```{r}
summary_table <- covar_df %>%
  group_by(education, sex) %>%
  summarize(count = n()) %>%
  pivot_wider(names_from = sex, values_from = count, names_prefix = "count_")

colnames(summary_table)[2:3] <- c("male", "female")

knitr::kable(summary_table)

age_distribution_plot <- covar_df %>%
  ggplot(aes(x = age, fill = sex)) +
  geom_histogram(position = "identity", alpha = 0.7, bins = 10) +
  facet_grid(sex ~ education) +
  labs(
    title = "Age Distributions by Education and Sex",
    x = "Age",
    y = "Frequency"
  ) +
  theme_minimal()

print(age_distribution_plot)
```

From the table, we can see that in our dataset, there are slightly more females than males who have an education level of less than HS, more males than females who have an education level of HS equivalent, and slightly more females than males with an education of more than HS. 

The distribution of age is approximately left skewed for men with education level less than high school. The distribution of age is bimodal for men with education of HS equivalent. The distributuion of age is approximately uniform for men with education of more than HS. 

The distribution of age is approximately uniform for women with education level less than high school. The distribution of age is left skewed for women with education of HS equivalent. The distribution of age is right skewed for women with education of more than HS. 

```{r}
ggplot(covar_df, aes(x = education, y = age, fill = sex)) +
  geom_boxplot() +
  labs(title = "Age Distribution by Education and Gender", x = "Education", y = "Age") +
  theme_minimal()
```

We can see from the side-by-side box plots: the median age of men and women who had an education of less than HS is around 60, the median age of men is lower than the median age of women for education of HS equivalent, and the median age of men and women who had an education of more than HS is around 40.  

Creating a total_count variable in the dataframe that accumulates the min_x values. 
```{r}
accel_df <- accel_df %>% 
  mutate(total_count = rowSums(select(.,seqn)))
head(accel_df)
```

Combining the two dataframs by seqn ID
```{r}
combined_df <- covar_df %>% inner_join(accel_df, by = "seqn")
head(combined_df)
```

```{r}
ggplot(combined_df, aes(x = age, y = total_count, color = sex)) +
  geom_point() +
  facet_grid(. ~ education) +
  geom_smooth(method = "loess", se = FALSE) +  # Add a loess curve without a confidence interval
  labs(
    title = "Total Activity vs. Age by Education and Gender",
    x = "Age",
    y = "Total Activity"
  ) +
  theme_minimal()
```

Overall: the total activity of male and female with education level less than HS decreases as age increases, the total activity of male and female with education level of HS equivalent increases as age increases, the total activity of male with education level of more than high school stays about the same as age increases, the total activity of women with education level of more than high school increases as age increases. 

```{r}
combined_df <- 
  combined_df %>% 
  pivot_longer(cols = starts_with("min"), names_to = "min", values_to = "activity") %>% 
  mutate(min = str_remove(min, "min")) %>% 
  mutate(min = as.integer(min)) %>% 
  ggplot(aes(x = min, y = activity, color = sex)) +
  geom_point(alpha = .1) +
  geom_smooth(se = F) +
  facet_wrap(~education)

combined_df
```

Overall: for all three education levels, as time passes, the activity increases but slowly starts to decrease again. 








